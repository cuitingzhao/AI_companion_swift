# Chat API Documentation

Source file: [`app/api/v1/endpoints/chat.py`](../app/api/v1/endpoints/chat.py)

## 1. POST `/api/v1/chat/message`

Process a user message in the main companion chat with optional tool calling support.

### Description

This is the primary chat endpoint for the AI companion. It:

1. **Builds context** from user profile, Bazi chart, personality analysis
2. **Injects tool capabilities** (L0 index) into the system prompt
3. **Calls AI model** with tool definitions (L1 schemas) if enabled
4. **Executes tools** automatically when AI requests them (e.g., ganzhi calculator, goal manager)
5. **Returns response** with reply, tool execution records, and any `pending_client_actions` for the client to handle

### Query Parameters

| Parameter | Type | Default | Description |
| --- | --- | --- | --- |
| `enable_tools` | boolean | `true` | Enable tool calling capabilities. Set to `false` to disable tools. |

### Request Body â€” [`ChatMessageRequest`](../app/schemas/chat.py)

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `user_id` | integer | Yes | User ID (must be > 0). |
| `message` | string | Yes | User's chat message (1-4000 characters). |
| `model_name` | string | No | Optional model override. Defaults to `MODEL_MAIN_CHAT` env var or `deepseek-chat`. |

### Response â€” [`ChatMessageResponse`](../app/schemas/chat.py)

| Field | Type | Description |
| --- | --- | --- |
| `reply` | string | AI companion's reply to the user. |
| `tool_calls_made` | array of `ToolCallRecord` | Tools called during this chat turn. Empty if no tools invoked. |
| `pending_client_actions` | array of `PendingClientAction` | Actions for iOS client to execute locally (calendar, alarm, goal wizard, etc.). |

#### `ToolCallRecord` Structure

| Field | Type | Description |
| --- | --- | --- |
| `tool` | string | Name of the tool that was called. |
| `arguments` | object | Arguments passed to the tool. |
| `result` | object | Result returned by the tool execution. |

#### `PendingClientAction` Structure

| Field | Type | Description |
| --- | --- | --- |
| `tool` | string | Name of the client-side action source (e.g., `calendar_manager`, `alarm_manager`, `goal_wizard`). |
| `action` | string | Action to perform (e.g., `create_event`, `create_alarm`, `start`). |
| `params` | object | Parameters for the action. |

### Available Tools

When `enable_tools=true`, the AI can call these tools:

| Tool Name | Description | Use Case | Execution |
| --- | --- | --- | --- |
| `ganzhi_calculator` | è®¡ç®—æŒ‡å®šæ—¥æœŸçš„å¤©å¹²åœ°æ”¯ä¿¡æ¯ | ç”¨æˆ·è¯¢é—®è¿åŠ¿ã€æµå¹´æµæœˆæ—¶ | Backend |
| `goal_manager` | ç®¡ç†ç”¨æˆ·çš„ç›®æ ‡ã€é‡Œç¨‹ç¢‘å’Œä»»åŠ¡ | ç”¨æˆ·æŸ¥è¯¢æˆ–æ›´æ–°ç›®æ ‡è¿›åº¦æ—¶ | Backend |
| `goal_wizard` | å¯åŠ¨ç›®æ ‡è®¾å®šå‘å¯¼ï¼ˆå®¢æˆ·ç«¯å¤šæ­¥æµç¨‹ï¼‰ | ç”¨æˆ·æ˜ç¡®è¡¨è¾¾æƒ³è®¤çœŸè®¾å®š/è°ƒæ•´ç›®æ ‡ï¼Œå¹¶åŒæ„è¿›å…¥å‘å¯¼æ—¶ | Clientï¼ˆé€šè¿‡ `pending_client_actions` è§¦å‘å‘å¯¼ UIï¼‰ |
| `web_search` | æœç´¢äº’è”ç½‘è·å–æœ€æ–°ä¿¡æ¯ | ç”¨æˆ·è¯¢é—®æ–°é—»ã€å®æ—¶ä¿¡æ¯æ—¶ | Backend (Kimi web_search agent, Tavily fallback) |
| `calendar_manager` | ç®¡ç†æ—¥å†æ—¥ç¨‹ | ç”¨æˆ·åˆ›å»º/æŸ¥çœ‹æ—¥ç¨‹æ—¶ | iOS Client |
| `alarm_manager` | åˆ›å»ºå’Œç®¡ç†é—¹é’Ÿ | ç”¨æˆ·è®¾ç½®é—¹é’Ÿæ—¶ | iOS Client |
| `health_data` | æŸ¥è¯¢å¥åº·æ•°æ® | ç”¨æˆ·è¯¢é—®æ­¥æ•°/ç¡çœ /è¿åŠ¨æ—¶ | iOS Client |
| `screen_time` | æŸ¥è¯¢å±å¹•ä½¿ç”¨æ—¶é—´ | ç”¨æˆ·è¯¢é—®æ‰‹æœºä½¿ç”¨æƒ…å†µæ—¶ | iOS Client |

#### `ganzhi_calculator` Arguments

| Argument | Type | Required | Description |
| --- | --- | --- | --- |
| `date` | string | No | Date in YYYY-MM-DD format. Defaults to today. |
| `time_unit` | string | Yes | `"day"`, `"month"`, or `"year"` for pillar type. |

#### `goal_manager` Arguments

| Argument | Type | Required | Description |
| --- | --- | --- | --- |
| `action` | string | Yes | One of: `list_goals`, `get_goal_detail`, `update_goal`, `update_milestone`, `update_task`, `create_task`. |
| `goal_id` | string | Depends | Required for most actions except `list_goals`. |
| `milestone_id` | string | Depends | Required for milestone/task operations. |
| `task_id` | string | Depends | Required for `update_task`. |
| `updates` | object | Depends | Fields to update or create. |

#### `goal_wizard` Arguments

| Argument | Type | Required | Description |
| --- | --- | --- | --- |
| `candidate_description` | string | Yes | AI æ€»ç»“çš„ç›®æ ‡å€™é€‰æè¿°ï¼Œ1â€“2 å¥è‡ªç„¶è¯­è¨€ï¼Œç”¨äºåœ¨å®¢æˆ·ç«¯å‘å¯¼ä¸­é¢„å¡«ã€‚ |
| `source` | string | No | è§¦å‘æ¥æºï¼Œä¾‹å¦‚ `"chat"` æˆ– `"manual"`ã€‚é»˜è®¤ç”±åç«¯å¡«ä¸º `"chat"`ã€‚ |

#### `web_search` Arguments

| Argument | Type | Required | Description |
| --- | --- | --- | --- |
| `query` | string | Yes | Search query. |
| `search_depth` | string | No | `"basic"` or `"advanced"`. Default: `"basic"`. |
| `max_results` | integer | No | Number of results (1-10). Default: 5. |

#### iOS Native Tools (calendar_manager, alarm_manager, health_data, screen_time)

These tools return `pending_client_actions` instead of executing directly. The iOS client should:
1. Check if user has granted required permissions
2. Request permission if needed
3. Execute the action using native iOS APIs
4. Optionally report result back to the chat

See `PendingClientAction` structure above for the response format.

#### Goal Wizard Trigger (goal_wizard)

The `goal_wizard` tool is a **trigger** for a client-side goal setting wizard. It does not
create or update goals directly. Instead, the backend returns a `pending_client_action` like:

```json
{
  "tool": "goal_wizard",
  "action": "start",
  "params": {
    "candidate_description": "åœ¨ä¸€å¹´å†…åšæŒé”»ç‚¼ï¼Œè®©ä½“è„‚é™åˆ°20%å·¦å³",
    "source": "chat",
    "user_id": "1"
  }
}
```

The mobile app should:
1. Inspect `pending_client_actions` in the `ChatMessageResponse`.
2. When it finds an action with `tool = "goal_wizard"` and `action = "start"`,
   open the dedicated goal wizard UI.
3. Use `candidate_description` to pre-fill the wizard with the AI's understanding
   of the goal candidate.

### Example Request

```bash
curl -X POST "http://localhost:8000/api/v1/chat/message?enable_tools=true" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "message": "ä»Šå¤©è¿åŠ¿æ€ä¹ˆæ ·ï¼Ÿ"
  }'
```

### Example Response (with tool call)

```json
{
  "reply": "è®©æˆ‘å¸®ä½ æŸ¥ä¸€ä¸‹ä»Šå¤©çš„å¹²æ”¯ä¿¡æ¯ã€‚ä»Šå¤©æ˜¯ä¹™å·³æ—¥ï¼Œå·³ç«è—ä¸™ã€åºšã€æˆŠã€‚ä»å…«å­—è§’åº¦æ¥çœ‹ï¼Œä»Šå¤©ç«æ°”è¾ƒæ—º...",
  "tool_calls_made": [
    {
      "tool": "ganzhi_calculator",
      "arguments": {
        "time_unit": "day"
      },
      "result": {
        "success": true,
        "result": {
          "label": "æ—¥æŸ±",
          "ganzhi": "ä¹™å·³",
          "heavenly_stem": "ä¹™",
          "earthly_branch": "å·³",
          "hidden_stems": ["ä¸™", "åºš", "æˆŠ"],
          "query_date": "2025-11-25",
          "time_unit": "day"
        }
      }
    }
  ]
}
```

### Example Response (with iOS native tool)

```json
{
  "reply": "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ è®¾ç½®æ˜æ—©7ç‚¹çš„é—¹é’Ÿã€‚",
  "tool_calls_made": [
    {
      "tool": "alarm_manager",
      "arguments": {
        "action": "create_alarm",
        "time": "07:00",
        "label": "èµ·åºŠ"
      },
      "result": {
        "status": "pending_client_action",
        "message": "é—¹é’Ÿæ“ä½œ 'create_alarm' å·²å‡†å¤‡å¥½ï¼Œç­‰å¾…å®¢æˆ·ç«¯æ‰§è¡Œ",
        "pending_client_action": {
          "tool": "alarm_manager",
          "action": "create_alarm",
          "params": {
            "time": "07:00",
            "label": "èµ·åºŠ"
          }
        }
      }
    }
  ],
  "pending_client_actions": [
    {
      "tool": "alarm_manager",
      "action": "create_alarm",
      "params": {
        "time": "07:00",
        "label": "èµ·åºŠ"
      }
    }
  ]
}
```

### Example Response (with goal wizard trigger)

```json
{
  "reply": "å¬èµ·æ¥è¿™æ˜¯ä¸€ä¸ªå¯¹ä½ å¾ˆé‡è¦çš„é•¿æœŸç›®æ ‡ã€‚å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªå°å‘å¯¼ä¸€æ­¥æ­¥å¸®ä½ æŠŠè¿™ä¸ªç›®æ ‡ç†æ¸…æ¥šã€‚",
  "tool_calls_made": [
    {
      "tool": "goal_wizard",
      "arguments": {
        "candidate_description": "åœ¨ä¸€å¹´å†…åšæŒé”»ç‚¼ï¼Œè®©ä½“è„‚é™åˆ°20%å·¦å³",
        "source": "chat"
      },
      "result": {
        "status": "pending_client_action",
        "message": "ç›®æ ‡è®¾å®šå‘å¯¼å·²å‡†å¤‡å¥½ï¼Œç­‰å¾…å®¢æˆ·ç«¯æ‰§è¡Œ",
        "pending_client_action": {
          "tool": "goal_wizard",
          "action": "start",
          "params": {
            "candidate_description": "åœ¨ä¸€å¹´å†…åšæŒé”»ç‚¼ï¼Œè®©ä½“è„‚é™åˆ°20%å·¦å³",
            "source": "chat",
            "user_id": "1"
          }
        }
      }
    }
  ],
  "pending_client_actions": [
    {
      "tool": "goal_wizard",
      "action": "start",
      "params": {
        "candidate_description": "åœ¨ä¸€å¹´å†…åšæŒé”»ç‚¼ï¼Œè®©ä½“è„‚é™åˆ°20%å·¦å³",
        "source": "chat",
        "user_id": "1"
      }
    }
  ]
}
```

### Example Response (simple reply)

```json
{
  "reply": "å“ˆå“ˆï¼Œä»Šå¤©å¿ƒæƒ…ä¸é”™å˜›ï¼æœ‰ä»€ä¹ˆå¼€å¿ƒçš„äº‹æƒ…æƒ³åˆ†äº«å—ï¼ŸğŸ˜Š",
  "tool_calls_made": [],
  "pending_client_actions": []
}
```

### Errors

| Status Code | Description |
| --- | --- |
| `422 Unprocessable Entity` | Invalid request body (missing fields, invalid types). |
| `500 Internal Server Error` | AI model error or unexpected failure. |

### Notes

1. **Tool Execution Loop**: When AI decides to use a tool, the system automatically executes it and feeds the result back to the AI. This may happen multiple times (up to 2 rounds) before a final response.

2. **Follow-up Memory**: Follow-up events are managed by an offline batch job, not during chat. The chat agent is aware of active follow-up events for context but does not create or update them in real-time.

3. **Context Building**: The system automatically includes:
   - User profile (nickname, age, gender, personality)
   - Bazi chart information (if available)
   - Active follow-up events due for today
   - **Recent conversation history** (last 10 messages for continuity)

4. **Model Selection**: Default model is `deepseek-chat`. Override via `model_name` in request or `MODEL_MAIN_CHAT` environment variable.

5. **Message Persistence**: All user and assistant messages are automatically saved to the conversation history.

---

## 1.1 Streaming Variant: POST `/api/v1/chat/message/stream`

Stream the AI companion reply token-by-token using **Server-Sent Events (SSE)**.

This endpoint shares the same request body as `POST /api/v1/chat/message` but
returns a streaming response instead of a single JSON object.

### Description

This streaming endpoint:

1. Builds the same rich system prompt (user profile, Bazi, goals, followups).
2. **Disables backend tool execution in v1** to keep the stream simple and
   predictable â€“ the model focuses purely on generating a conversational reply.
3. Streams tokens as they are generated by the model via SSE events.
4. On completion, persists both the user message and the final assistant reply
   into the conversation history.

Use this when you want a more responsive chat UI where the user can see the
assistant typing in real time.

### Request

- **Method:** `POST`
- **Path:** `/api/v1/chat/message/stream`
- **Headers:**
  - `Content-Type: application/json`
  - `Accept: text/event-stream`
- **Body:** `ChatMessageRequest` (same as `/message`)

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `user_id` | integer | Yes | User ID (must be > 0). |
| `message` | string | Yes | User's chat message (1-4000 characters). |
| `model_name` | string | No | Optional model override. Defaults to `MODEL_MAIN_CHAT` env var or `deepseek-chat`. |

### Response â€” SSE Event Stream

- **Content-Type:** `text/event-stream`
- The response is a sequence of SSE events separated by blank lines.

#### Event Types

| Event | Description | Data Payload Example |
| --- | --- | --- |
| `token` | A partial piece of the assistant reply. Append `content` to the UI buffer. | `{"content": "ä½ å¥½"}` |
| `done` | Final event with the full reply and optional `events` array. | `{"reply": "å®Œæ•´å›å¤...", "events": []}` |
| `error` | Indicates a failure during streaming. | `{"error": "Internal server error"}` |

##### `token` Events

```text
event: token
data: {"content": "ä½ å¥½"}

event: token
data: {"content": "ï¼Œæˆ‘æ˜¯ä½ çš„AIä¼™ä¼´"}
```

The client should append each `content` value to the on-screen message as it
arrives.

##### `done` Event

```text
event: done
data: {
  "reply": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„ AI ä¼™ä¼´ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼",
  "events": []
}
```

- `reply`: Final assistant reply string (may be derived from structured JSON
  `{ reply, events }` when the model follows the contract).
- `events`: Optional follow-up memory payload, same structure as
  `ChatEventPayload` used in `/message`.

##### `error` Event

```text
event: error
data: {"error": "Configuration for model 'xxx' not found."}
```

The client should treat this as a terminal failure for the stream.

### Behavior and Limitations

- **No tools in v1:**
  - The backend passes `tools=None` to the model in streaming mode.
  - The prompt explicitly tells the model that tools are not available in this
    mode.
  - If you need tool execution (e.g., web_search, calendar, alarm), you should
    use the non-streaming `POST /api/v1/chat/message` endpoint.

- **Message persistence:**
  - On the `done` event, the backend saves:
    - The user message (role `user`).
    - The final assistant reply (role `assistant`) with token counts when
      available.

- **Structured JSON output:**
  - If the model returns a JSON object like `{ "reply": "...", "events": [...] }`
    as the final text, the backend will parse it and expose:
    - `reply`: from the JSON.
    - `events`: from the JSON.
  - If parsing fails, the raw text is used as `reply` and `events` defaults to `[]`.

### Example Streaming Request (curl)

```bash
curl -N \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{
    "user_id": 1,
    "message": "ç®€å•è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹å§"
  }' \
  http://localhost:8000/api/v1/chat/message/stream
```

The `-N` flag tells `curl` to disable buffering so you can see tokens as they arrive.

---

## 2. GET `/api/v1/chat/history/{user_id}`

Get paginated chat history for a user.

### Description

Returns chat messages in chronological order (oldest first). Supports cursor-based pagination for loading older messages.

### Path Parameters

| Parameter | Type | Description |
| --- | --- | --- |
| `user_id` | integer | User ID |

### Query Parameters

| Parameter | Type | Default | Description |
| --- | --- | --- | --- |
| `limit` | integer | `50` | Maximum messages to return (1-200). |
| `before_id` | integer | `null` | Return messages before this message ID (for pagination). |

### Response â€” [`ChatHistoryResponse`](../app/schemas/chat.py)

| Field | Type | Description |
| --- | --- | --- |
| `messages` | array of `ChatHistoryMessage` | Messages in chronological order (oldest first). |
| `has_more` | boolean | Whether there are more messages before the returned set. |
| `oldest_id` | integer \| null | ID of the oldest message returned (use as `before_id` for next page). |
| `conversation_id` | integer \| null | ID of the main chat conversation. |

#### `ChatHistoryMessage` Structure

| Field | Type | Description |
| --- | --- | --- |
| `id` | integer | Message ID. |
| `role` | string | Message role: `"user"` or `"assistant"`. |
| `content` | string | Message content. |
| `created_at` | string (ISO datetime) | When the message was created. |
| `tool_calls` | array \| null | Tool calls made during this message (if any). |

### Example Request

```bash
# Get latest 50 messages
curl "http://localhost:8000/api/v1/chat/history/1"

# Get 20 messages before message ID 100
curl "http://localhost:8000/api/v1/chat/history/1?limit=20&before_id=100"
```

### Example Response

```json
{
  "messages": [
    {
      "id": 95,
      "role": "user",
      "content": "ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½",
      "created_at": "2025-11-25T10:30:00",
      "tool_calls": null
    },
    {
      "id": 96,
      "role": "assistant",
      "content": "æ€ä¹ˆäº†ï¼Ÿå‘ç”Ÿä»€ä¹ˆäº‹äº†å—ï¼Ÿæˆ‘åœ¨è¿™é‡Œå¬ä½ è¯´ ğŸ˜Š",
      "created_at": "2025-11-25T10:30:05",
      "tool_calls": null
    },
    {
      "id": 97,
      "role": "user",
      "content": "å·¥ä½œå‹åŠ›å¤ªå¤§äº†",
      "created_at": "2025-11-25T10:31:00",
      "tool_calls": null
    },
    {
      "id": 98,
      "role": "assistant",
      "content": "å·¥ä½œå‹åŠ›å¤§ç¡®å®å¾ˆç´¯äººã€‚èƒ½è·Ÿæˆ‘è¯´è¯´å…·ä½“æ˜¯ä»€ä¹ˆè®©ä½ æ„Ÿåˆ°å‹åŠ›å—ï¼Ÿ",
      "created_at": "2025-11-25T10:31:08",
      "tool_calls": null
    }
  ],
  "has_more": true,
  "oldest_id": 95,
  "conversation_id": 1
}
```

### Pagination Flow

1. **Initial load**: Call without `before_id` to get the most recent messages.
2. **Load older**: Use `oldest_id` from response as `before_id` in next request.
3. **Stop when**: `has_more` is `false`.

```
Initial:  GET /chat/history/1?limit=50
          â†’ messages[0..49], oldest_id=50, has_more=true

Page 2:   GET /chat/history/1?limit=50&before_id=50
          â†’ messages[0..49], oldest_id=1, has_more=false
```

### Errors

| Status Code | Description |
| --- | --- |
| `500 Internal Server Error` | Database or unexpected failure. |

---

## 3. GET `/api/v1/chat/greeting/{user_id}`

Generate a personalized AI greeting when user opens the chat.

### Description

Returns a warm, contextual greeting based on:
- **Time of day** (æ—©ä¸Šå¥½/ä¸‹åˆå¥½/æ™šä¸Šå¥½)
- **Recent conversation history** (can reference last topic)
- **Pending follow-up events** (can mention things to check on)

Call this endpoint when the user opens the chat interface to display a personalized welcome message instead of an empty screen.

### Path Parameters

| Parameter | Type | Description |
| --- | --- | --- |
| `user_id` | integer | User ID |

### Response â€” [`ChatGreetingResponse`](../app/schemas/chat.py)

| Field | Type | Description |
| --- | --- | --- |
| `greeting` | string | Personalized greeting message from the AI companion. |
| `has_pending_followups` | boolean | Whether there are pending follow-up events to discuss. |
| `is_returning_user` | boolean | Whether this user has chatted before. |

### Example Request

```bash
curl "http://localhost:8000/api/v1/chat/greeting/1"
```

### Example Responses

**New user (morning):**
```json
{
  "greeting": "æ—©ä¸Šå¥½å‘€ â˜€ï¸ ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿ",
  "has_pending_followups": false,
  "is_returning_user": false
}
```

**Returning user with recent conversation:**
```json
{
  "greeting": "ä¸‹åˆå¥½ï¼ä¸Šæ¬¡èŠåˆ°å·¥ä½œå‹åŠ›çš„äº‹ï¼Œç°åœ¨å¥½äº›äº†å—ï¼Ÿ",
  "has_pending_followups": true,
  "is_returning_user": true
}
```

**Returning user (evening):**
```json
{
  "greeting": "æ™šä¸Šå¥½å‘€ï½ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿ",
  "has_pending_followups": false,
  "is_returning_user": true
}
```

### Mobile App Integration

```
User opens chat screen
    â†“
App calls GET /chat/greeting/{user_id}
    â†“
Display greeting as first message (assistant bubble)
    â†“
Load chat history below greeting
    â†“
User can respond or scroll to see history
```

### Errors

| Status Code | Description |
| --- | --- |
| `404 Not Found` | User not found. |
| `500 Internal Server Error` | AI generation or database failure. |



## Appendix. Permission Request Flow Example
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PERMISSION REQUEST FLOW                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User: "å¸®æˆ‘è®¾ä¸ªæ˜æ—©7ç‚¹çš„é—¹é’Ÿ"
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend returns:                                                 â”‚
â”‚ {                                                                â”‚
â”‚   "reply": "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ è®¾ç½®æ˜æ—©7ç‚¹çš„é—¹é’Ÿ",                    â”‚
â”‚   "pending_client_actions": [{                                   â”‚
â”‚     "tool": "alarm_manager",                                     â”‚
â”‚     "action": "create_alarm",                                    â”‚
â”‚     "params": {"time": "07:00"}                                  â”‚
â”‚   }]                                                             â”‚
â”‚ }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ iOS Client checks permission status:                             â”‚
â”‚                                                                  â”‚
â”‚ if permission_not_granted:                                       â”‚
â”‚   - Show system permission dialog                                â”‚
â”‚   - If denied: show explanation + settings link                  â”‚
â”‚ else:                                                            â”‚
â”‚   - Execute the action                                           â”‚
â”‚   - Report result back to chat (optional)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
### Permission Groups:
Tool| iOS Permission	| When to Request
calendar_manager | EventKit (Calendar) | First calendar action
alarm_manager | None (uses Clock app URL scheme) | N/A
health_data | HealthKit | First health query
screen_time | Screen Time API | First screen time query

### Best Practices:

- Don't request all permissions upfront - Users are more likely to grant when they understand why
- Show context before requesting - "ä¸ºäº†å¸®ä½ æŸ¥çœ‹æ—¥ç¨‹ï¼Œéœ€è¦è®¿é—®ä½ çš„æ—¥å†"
- Handle denial gracefully - AI can respond: "æ²¡å…³ç³»ï¼Œä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨æŸ¥çœ‹æ—¥å†"
- Cache permission status - Don't repeatedly ask if already denied
